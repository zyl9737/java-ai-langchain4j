#web port
server.port=10324
# openai deepseek
#langchain4j.open-ai.chat-model.base-url=https://api.deepseek.com
#langchain4j.open-ai.chat-model.api-key=${DEEP_SEEK_API_KEY}
#langchain4j.open-ai.chat-model.model-name=deepseek-chat

#ali-deepseek
langchain4j.open-ai.chat-model.base-url=https://dashscope.aliyuncs.com/compatible-mode/v1
langchain4j.open-ai.chat-model.api-key=${DASH_SCOPE_API_KEY}
langchain4j.open-ai.chat-model.model-name=deepseek-v3
langchain4j.open-ai.chat-model.temperature=0.9

#log
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true
# ollama
langchain4j.ollama.chat-model.base-url=http://172.31.109.43:11434
langchain4j.ollama.chat-model.model-name=gemma3:27b
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true
# Qwen
langchain4j.community.dashscope.chat-model.api-key=${DASH_SCOPE_API_KEY}
langchain4j.community.dashscope.chat-model.model-name=qwen-max


# log level
#logging.level.root=debug
spring.data.mongodb.uri=mongodb://localhost:27017/chat_memory_db
